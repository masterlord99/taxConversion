url = list(
AT="https://feeds.adzuna.co.uk/oecd/jobs_AT_4695.xml.gz",
AU="https://feeds.adzuna.co.uk/oecd/jobs_AU_515.xml.gz",
BR="https://feeds.adzuna.co.uk/oecd/jobs_BR_7966.xml.gz",
CA="https://feeds.adzuna.co.uk/oecd/jobs_CA_9655.xml.gz",
DE="https://feeds.adzuna.co.uk/oecd/jobs_DE_1976.xml.gz",
FR="https://feeds.adzuna.co.uk/oecd/jobs_FR_336.xml.gz",
IN="https://feeds.adzuna.co.uk/oecd/jobs_IN_8576.xml.gz",
IT="https://feeds.adzuna.co.uk/oecd/jobs_IT_7686.xml.gz",
NL="https://feeds.adzuna.co.uk/oecd/jobs_NL_8176.xml.gz",
NZ="https://feeds.adzuna.co.uk/oecd/jobs_NZ_9571.xml.gz",
PL="https://feeds.adzuna.co.uk/oecd/jobs_PL_9533.xml.gz",
RU="https://feeds.adzuna.co.uk/oecd/jobs_RU_2019.xml.gz",
SG="https://feeds.adzuna.co.uk/oecd/jobs_SG_7010.xml.gz",
US="https://feeds.adzuna.co.uk/oecd/jobs_US_7368.xml.gz",
UK="https://feeds.adzuna.co.uk/oecd/jobs_3169.xml.gz",
ZA="https://feeds.adzuna.co.uk/oecd/jobs_ZA_2143.xml.gz"
)
i = url["ZA"]
download.file(i)
basename(i)
i = url["ZA"]
basename(i)
basename(i$ZA)
i = url[["ZA"]]
download.file(i,destfile = basename(i))
unzip(basename(i))
system(paste0("gzip ",basename(i)))
?gzfile()
gzfile(basename(i))
file = read.table(gzfile(basename(i)))
file = data.table::fread(gzfile(basename(i)))
install.packages("XML")
file = XML::xmlToDataFrame(gzfile(basename(i)))
library(XML)
?xmlToDataFrame
file = XML::xmlToDataFrame(basename(i))
## load
download.file(i,destfile = basename(i))
## unzip
system(paste0("gzip -d ",basename(i)))
## unzip
system(paste0("gzip -d ",basename(i)))
basename(i)
dirname(i)
i
gsub(basename(i),".gz","")
gsub(basename(i),".gz",replacement = "")
gsub(basename(i),pattern = ".gz",replacement = "")
## read
file = XML::xmlToDataFrame(gsub(basename(i),pattern = ".gz",replacement = ""))
gsub(basename(i),pattern = ".gz",replacement = "")
## read
file = xml2::read_xml(gsub(basename(i),pattern = ".gz",replacement = ""))
file$node
file$doc
## read
data = xml2::read_xml(gsub(basename(i),pattern = ".gz",replacement = ""))
point <- data %>% xml_find_all("//point")
## read
library(magrittr)
point <- data %>% xml_find_all("//point")
## read
library(xml2)
point <- data %>% xml2::xml_find_all("//point")
point <- data %>% xml2::xml_find_all("//node")
point <- data %>% xml2::xml_find_all("//doc")
## read
file = XML::xmlToDataFrame(gsub(basename(i),pattern = ".gz",replacement = ""))
file = gsub(basename(i),pattern = ".gz",replacement = "")
data = XML::xmlParse(file)
xml_data = xmlToDataFrame(data)
xml_data = xmlToList(data)
head(xml_data)
xml_data[[1]]
xml_data[[1]] %>% unlist()
xml_data = lapply(xml_data,unlist)
xml_data = data.table::rbindlist(xml_data,fill = T,use.names = T)
len = lapply(xml_data,length) %>% unlist()
unique(len)
a = xml_data[[1]]
a
as.list(a)
xml_data = lapply(xml_data,function(x)as.list(unlist(x)))
xml_data = data.table::rbindlist(xml_data)
xml_data = data.table::rbindlist(xml_data,fill = T,use.names = T)
max(len)
xml_data = data.table::rbindlist(xml_data,fill = T,use.names = T) %>% as.data.frame()
setwd("~/Desktop/githubX/ProjectX/BCH/bayes")
vars <- readRDS("~/Desktop/githubX/ProjectX/BCH/bayes/tmp_best_vars.RDS")
vars
setwd("~/Desktop/adzuna_stream")
list.files()
setwd("tmp")
list.files()
file.create("a.txt")
download.file(i,destfile = basename(i))
list.files()
lapply(list.files(),file.remove)
setwd("..")
message(i," downloaded and processed! Saving RDS!")
unlink("tmp",recursive = T,force = T)
message("FILE: ",i," downloaded and processed! Saving RDS!")
message("FILE:     ",i,"    downloaded and processed! Saving RDS!")
message("FILE:  ~   ",i,"    downloaded and processed! Saving RDS!")
message("FILE:    ",i,"    downloaded and processed! Saving RDS!")
download_and_process_to_raw <- function(i){
dir.create("tmp")
Sys.sleep(2)
setwd("tmp")
download.file(i,destfile = basename(i))
## unzip
system(paste0("gzip -d ",basename(i)))
## read
file = XML::xmlToDataFrame(gsub(basename(i),pattern = ".gz",replacement = ""))
file = gsub(basename(i),pattern = ".gz",replacement = "")
data = XML::xmlParse(file)
xml_data = xmlToList(data)
xml_data = lapply(xml_data,function(x)as.list(unlist(x)))
xml_data = data.table::rbindlist(xml_data,fill = T,use.names = T) %>% as.data.frame()
lapply(list.files(),file.remove)
setwd("..")
message("FILE:    ",i,"    downloaded and processed! Saving RDS!")
unlink("tmp",recursive = T,force = T)
return(xml_data)
}
url = list(
AT="https://feeds.adzuna.co.uk/oecd/jobs_AT_4695.xml.gz",
AU="https://feeds.adzuna.co.uk/oecd/jobs_AU_515.xml.gz",
BR="https://feeds.adzuna.co.uk/oecd/jobs_BR_7966.xml.gz",
CA="https://feeds.adzuna.co.uk/oecd/jobs_CA_9655.xml.gz",
DE="https://feeds.adzuna.co.uk/oecd/jobs_DE_1976.xml.gz",
FR="https://feeds.adzuna.co.uk/oecd/jobs_FR_336.xml.gz",
IN="https://feeds.adzuna.co.uk/oecd/jobs_IN_8576.xml.gz",
IT="https://feeds.adzuna.co.uk/oecd/jobs_IT_7686.xml.gz",
NL="https://feeds.adzuna.co.uk/oecd/jobs_NL_8176.xml.gz",
NZ="https://feeds.adzuna.co.uk/oecd/jobs_NZ_9571.xml.gz",
PL="https://feeds.adzuna.co.uk/oecd/jobs_PL_9533.xml.gz",
RU="https://feeds.adzuna.co.uk/oecd/jobs_RU_2019.xml.gz",
SG="https://feeds.adzuna.co.uk/oecd/jobs_SG_7010.xml.gz",
US="https://feeds.adzuna.co.uk/oecd/jobs_US_7368.xml.gz",
UK="https://feeds.adzuna.co.uk/oecd/jobs_3169.xml.gz",
ZA="https://feeds.adzuna.co.uk/oecd/jobs_ZA_2143.xml.gz"
)
download_and_process_to_raw <- function(i){
dir.create("tmp")
Sys.sleep(2)
setwd("tmp")
download.file(i,destfile = basename(i))
## unzip
system(paste0("gzip -d ",basename(i)))
## read
file = XML::xmlToDataFrame(gsub(basename(i),pattern = ".gz",replacement = ""))
file = gsub(basename(i),pattern = ".gz",replacement = "")
data = XML::xmlParse(file)
xml_data = XML::~xmlToList(data)
xml_data = lapply(xml_data,function(x)as.list(unlist(x)))
xml_data = data.table::rbindlist(xml_data,fill = T,use.names = T) %>% as.data.frame()
lapply(list.files(),file.remove)
setwd("..")
message("FILE:    ",i,"    downloaded and processed! Saving RDS!")
unlink("tmp",recursive = T,force = T)
return(xml_data)
}
download_and_process_to_raw <- function(i){
dir.create("tmp")
Sys.sleep(2)
setwd("tmp")
download.file(i,destfile = basename(i))
## unzip
system(paste0("gzip -d ",basename(i)))
## read
file = XML::xmlToDataFrame(gsub(basename(i),pattern = ".gz",replacement = ""))
file = gsub(basename(i),pattern = ".gz",replacement = "")
data = XML::xmlParse(file)
xml_data = XML::~xmlToList(data)
xml_data = lapply(xml_data,function(x)as.list(unlist(x)))
xml_data = data.table::rbindlist(xml_data,fill = T,use.names = T) %>% as.data.frame()
lapply(list.files(),file.remove)
setwd("..")
message("FILE:    ",i,"    downloaded and processed! Saving RDS!")
unlink("tmp",recursive = T,force = T)
return(xml_data)
}
download_and_process_to_raw <- function(i){
dir.create("tmp")
Sys.sleep(2)
setwd("tmp")
download.file(i,destfile = basename(i))
## unzip
system(paste0("gzip -d ",basename(i)))
## read
file = XML::xmlToDataFrame(gsub(basename(i),pattern = ".gz",replacement = ""))
file = gsub(basename(i),pattern = ".gz",replacement = "")
data = XML::xmlParse(file)
xml_data = XML::xmlToList(data)
xml_data = lapply(xml_data,function(x)as.list(unlist(x)))
xml_data = data.table::rbindlist(xml_data,fill = T,use.names = T) %>% as.data.frame()
lapply(list.files(),file.remove)
setwd("..")
message("FILE:    ",i,"    downloaded and processed! Saving RDS!")
unlink("tmp",recursive = T,force = T)
return(xml_data)
}
j 0 1
j = 1
country = url[j]
country[[1]]
data = download_and_process_to_raw(country[[1]])
httr::GET("status.kraken.com")
call = httr::GET("status.kraken.com")
cont = call$content %>% rawToChar() %>% jsonlite::toJSON()
library(magrittr)
cont = call$content %>% rawToChar() %>% jsonlite::toJSON()
cont = call$content %>% rawToChar() %>% jsonlite::fromJSON()
cont = call$content %>% rawToChar()
vars <- readRDS("~/Desktop/githubX/ProjectX/ETH/bayes/tmp_best_vars.RDS")
library(projectXcppCode)
process_bayes_variables(vars)
450727600
450/27600
450/27600/0.295
library(projectXcppCode)
setwd("~/Desktop/githubX/tecajDavki")
download.file("https://www.bsi.si/_data/tecajnice/dtecbs-l.xml","tmp.xml")
data <- XML::xmlParse("tmp.xml")
xml_data <- xmlToList(data)
xml_data <- XML::xmlToList(data)
x <- unlist(xml_data[[1]])
x
df <- as.data.frame(x)
df <- as.data.frame(t(df),stringsAsFactors = F)
df <- df[,1:102]
df <- df[,c(T,T,F)]
ime <- df[,c(F,T)]
valuta <- df[,c(T,F)]
im <- c()
for(i in 1:ncol(ime)){
im <- c(im,as.character(ime[1,i]))
}
colnames(valuta) <- im
df <- valuta
rm(ime,valuta,im)
df <- cbind(TIME=as.Date(tail(x,1)),df)
df <- df[,1:29]
df <- df[, colnames(df)!="ISK"]
df <- df[, colnames(df)!="BGN"]
w <- length(xml_data)
for(i in 2:(length(xml_data)-1)){
df[i,] <- NA
x <- unlist(xml_data[[i]])
df$TIME[i] <- tail(x,1) %>% as.Date()
for(j in 2:ncol(df)){
if(colnames(df)[j] %in% x){
ind <- which(x==colnames(df)[j]) %>% as.numeric()
df[i,j] <- x[ind - 1] %>% as.numeric()
}
}
print(i/w)
}
library(magrittr)
library(magrittr)
download.file("https://www.bsi.si/_data/tecajnice/dtecbs-l.xml","tmp.xml")
data <- XML::xmlParse("tmp.xml")
xml_data <- XML::xmlToList(data)
x <- unlist(xml_data[[1]])
df <- as.data.frame(x)
df <- as.data.frame(t(df),stringsAsFactors = F)
df <- df[,1:102]
df <- df[,c(T,T,F)]
ime <- df[,c(F,T)]
valuta <- df[,c(T,F)]
im <- c()
for(i in 1:ncol(ime)){
im <- c(im,as.character(ime[1,i]))
}
colnames(valuta) <- im
df <- valuta
rm(ime,valuta,im)
df <- cbind(TIME=as.Date(tail(x,1)),df)
df <- df[,1:29]
df <- df[, colnames(df)!="ISK"]
df <- df[, colnames(df)!="BGN"]
w <- length(xml_data)
for(i in 2:(length(xml_data)-1)){
df[i,] <- NA
x <- unlist(xml_data[[i]])
df$TIME[i] <- tail(x,1) %>% as.Date()
for(j in 2:ncol(df)){
if(colnames(df)[j] %in% x){
ind <- which(x==colnames(df)[j]) %>% as.numeric()
df[i,j] <- x[ind - 1] %>% as.numeric()
}
}
print(i/w)
}
#history <- df
kat <-  !(df$TIME %in% history$TIME)
history <- rbind(history,df[kat,])
View(df)
kat <-  !(df$TIME %in% history$TIME)
history <- df
kat <-  !(df$TIME %in% history$TIME)
history <- rbind(history,df[kat,])
history[,2:ncol(history)] <- apply(history[,2:ncol(history)],2,as.numeric)
View(history)
class(history$TIME)
View(df)
shiny::runApp()
runApp()
source("downloadData.R")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
colnames(df)
runApp()
runApp()
unique(history$TIME)
unique(history$TIME %>% year)
runApp()
?sliderInput
runApp()
runApp()
runApp()
as.Date(paste0(2020,10,12))
as.Date(paste0(2020,"-",10,"-",22))
runApp()
runApp()
ratio$v$date
max(ratio$v$date,Sys.Date())
ratio$v$date = max(ratio$v$date,Sys.Date())
paste0("Selected date: ",ratio$v$date)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
history$TIME
runApp()
tail(df)
runApp()
fluidPage(
title = "SacredConversion",
id = "mltwiz",
shinyjs::useShinyjs(),
setBackgroundImage("ahru.jpg",shinydashboard = F),
# tags$head(tags$script(js_)),
theme = shinytheme("paper"),
column(6,align="center",
br(),
br(),
br(),
br(),
br(),
br(),
dateInput("date","Select date:",min = min(df$TIME),max = max(df$TIME),value = max(df$TIME)),
br(),
h6(selectInput("curr","Currency:",choices = colnames(df)[-1])),
br(),
h4(textOutput("ratio"))
),
column(6,align="center",
br(),
br(),
br(),
br(),
br(),
br(),
br(),
)
)
shiny::runApp()
runApp()
Sys.Date() - 265
Sys.Date() - 365
runApp()
runApp()
shiny::runApp()
df$TIME
updateDateInput(session,"date",max = max(df$TIME),min=min(df$TIME))
shiny::runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
View(df)
runApp()
runApp()
runApp()
